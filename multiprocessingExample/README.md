# Multiprocessing in Python

For many of my solutions I was using the base threading library to develop and run multiple functions in "parallel". However, as I started to run simulations I started to really understand the drawback of the global interpreter lock in python. My goal was to run Monte Carlo simulations in distinct environments that were not dependent on each other. I noticed that the threading library really did not execute my code in parallel even if I wrote a "simulation" function that I wanted to execute. So then I turned to `multiprocessing`library in python. 

The multiprocessing package is similar to the threading package, as it allows develoeprs to spawn separate processes to accomplish tasks. The multiprocessing package offers both local and remote concurrency which effectively side-steps the Global Interpreter Lock by using subprocesses instead of threads. This means that developers are able to fully leverage multiple processors on a given machine. Please note that as while the threading library allows developers to share variables between threads, the multiprocessing library does not support this capability as easily. The best way to accomplish the sharing of data between threads is pass singleton classes to different processes so that the processes are able to update the class and broadcast updates. 

In this example, we create a simple function in the `functions.py` file that simply prints the datetime and value. The `run_example.py` file executes the function using the processing pool.  
